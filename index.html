<!DOCTYPE html>
<html>
<head>
    <title>yucxy</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="assets/css/main.css" />
    <noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
</head>
<body class="is-preload">
    <div id="wrapper">
        <header id="header">
            <div class="logo">
                <span class="icon solid fa-cogs"></span>
            </div>
            <div class="content">
                <div class="inner">
                    <h1>yucxy</h1>
                    <p>Homepage</p>
                </div>
            </div>
            <nav>
                <ul>
                    <!--Menu-->
                    <li><a href="#projects">Projects</a></li>
                    <li><a href="#cv">CV</a></li>
                    <li><a href="#about">About</a></li>
                    <li><a href="#blog">Blog</a></li>
                    <li><a href="#contact">Contact</a></li>
                </ul>
            </nav>
        </header>
        <div id="main">
            <!--contents for research-->
            <article id="projects">
                <!-- <a href="#header" class="close"></a> -->
                <h2 class="major">Projects</h2>
                
                <section>
                    <h3 class="major">SEMANTIC SEARCH</h3>
                    <h5>Purpose: To build a completely open-source applet using both front- and back-end techniques, to demonstrate an important concept in natural language processing (NLP) which is semantic searching.</h5>
                    <p>A common use of natural language today is to search the plethora of resources available online. A preliminary method is lexical search, which returns results based on the number of matching words and sometimes matching order of words from the search phrase.
                        However, often what we are searching for are resources with matching meaning, which do not necessarily have the greatest number of matching words. As such, semantic search, which returns results based on matching meaning instead, is preferred.
                    </p>
                    <p>The underlying mechanism of semantic search is as follows:
                        <span class="image"><img src="images/semantic_search.png" alt="" /></span>
                        <ol>
                            <li>Raw language is first split into meaningful pieces, commonly by words or partial words, called chunks</li>
                            <li>These chunks are passed to a trained large language model (LLM) which has learned how to best represent the semantic meaning behind each chunk in the form of a vector</li>
                            <li>When a question or query is searched, it is also split into chunks and vectorized, so that both the search and underlying resources are in similar, comparable forms</li>
                            <li>Since vectors are already semantic representations of the search and resources, the most relevant resource should be the closest to the search in the vector space</li>
                            <li>As such, we can use a distance measurement such as cosine distance, to find the resource which is closest to the search</li>
                            <li>Finally, the semantically closest resource is returned as the best-matching answer to search</li>
                        </ol>
                    </p>
                    <pre>
                        <code>
                            # load and split text
                            loader = PyPDFLoader(file_path)
                            docs = loader.load()
                            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, add_start_index=True)
                            all_splits = text_splitter.split_documents(docs)

                            # create vector store and store text embeddings
                            embedding_model = HuggingFaceEmbeddings(model_name=embedding_name)
                            vector_store = InMemoryVectorStore(embeddings)
                            _ = vector_store.add_documents(documents=all_splits)
                            
                            # query and get top semantic result
                            results = vector_store.similarity_search(question)
                            top = results[0].page_content
                        </code>
                    </pre>
                    <p></p>
                    <h6>Skills used: Python, PyTorch, Pandas, LangChain, html</h6>
                    <a href="#semsearch_demo">Click here for a demo on semantic search coming soon</a>
                    <p></p>
                    <a href="">Link to code on GitHub coming soon.</a>
                </section>
                <hr class="rounded">
                <section>
                    <h3 class="major">SEMANTIC SEARCH WITH CHAT</h3>
                    <h5>Purpose: To improve readability of the semantic search result for more natural, human interaction.</h5>
                    <p>From outputs of the above project, it can be noted that although query results have high semantic relevance, the output is not human-like and greatly resembles results from browser search engines.
                        Thus, to improve readability of the best semantically-matched result and make querying a more natural experience, a chat model is introduced to the pipeline.
                        <span class="image"><img src="images/semsearch_with_chat.png" alt="" /></span>
                    </p>
                    <pre>
                        <code>
                            # use semantic search and get top result
                            top = vecsearch_results[0].page_content

                            # initiate chat model
                            tokenizer = AutoTokenizer.from_pretrained(model_name)
                            model = AutoModelForCausalLM.from_pretrained(model_name)

                            # pass prompt containing top result to chat model and get readable response
                            text = tokenizer.apply_chat_template(history, tokenize=False, add_generation_prompt=True)
                            model_inputs = tokenizer([text], return_tensors="pt")
                            generated_ids = model.generate(**model_inputs)
                            output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()
                            response = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip("\n")
                        </code>
                    </pre>
                    <p></p>
                    <h6>Skills used: Python, HuggingFace, HuggingFace Spaces, Gradio, Git, html</h6>
                    <a href="#semsearch_with_chat_demo">Click here for a demo on semantic search with chat</a>
                    <p></p>
                    <a href="">Link to code on GitHub coming soon.</a>
                </section>
                <hr />
            </article>
            <article id="semsearch_demo">
                <h2 class="major">Semantic Search Demo</h2>
            </article>
            <article id="semsearch_with_chat_demo">
                <h2 class="major">Semantic Search Chat Demo</h2>
                <div class="iframe-container" height="450">
                    <div class="aspect-ratio-box">
                        <iframe 
                            class="responsive-iframe"
                            src="https://yucxy-semsearch-chat-demo.hf.space"
                            allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                            allowfullscreen
                        ></iframe>
                    </div>
                </div>

                <p>test</p>

                <p></p>
                <a href="#projects">Back to Projects</a>
            </article>

            <script>
                // Function to adjust iframe height based on content
                function adjustIframeHeight() {
                    const iframe = document.querySelector('.responsive-iframe');
                    const container = document.querySelector('.aspect-ratio-box');
                    
                    // Try to communicate with iframe content (if same-origin)
                    try {
                        iframe.onload = function() {
                            // This would work only if the iframe content is from the same origin
                            // For cross-origin iframes, we need to use other techniques
                            const iframeContentHeight = iframe.contentWindow.document.body.scrollHeight;
                            if (iframeContentHeight > 0) {
                                // Adjust the container's aspect ratio
                                const newAspectRatio = (iframeContentHeight / iframe.offsetWidth) * 100;
                                container.style.paddingTop = newAspectRatio + '%';
                            }
                        };
                    } catch (e) {
                        // Cross-origin issue, use a different approach
                        console.log("Cross-origin iframe, using fixed aspect ratio");
                    }
                }
                
                // Adjust on window resize
                window.addEventListener('resize', adjustIframeHeight);
                
                // Initial adjustment
                window.addEventListener('load', adjustIframeHeight);
            </script>

            
            <!--contents for cv-->
            <article id="cv">
                <!-- <a href="#header" class="close"></a> -->
                <h2 class="major">CV</h2>
                <blockquote>Interested in Data Scientist or AI Engineer roles with focus in Computer Vision and Large-Language Models (LLMs).
                    Based in Toronto, ON, Canada but also open to relocation to roles Canada-wide and in the US. <b>Does not require sponsorship to work in Canada.</b>
                </blockquote>
                <p></p>
                <h3 class="major">EDUCATION</h2>
                <ul class="Alternate">
                    <li>
                        <b>Master of Science</b>, 2022-2024<br>
                        Shanghai Jiao Tong University, School of Biomedical Engineering<br>
                        Thesis: Colo-segment recognition in video colonoscopies and its practical application<br>
                        Supervisor: Dr. Dahong Qian
                    </li>
                    <li>
                        <b>Honours, Bachelor of Science</b>, 2016-2020<br>
                        University of Toronto, Human Biology<br>
                        Honours Project: Effects of growth factors and cytokines on TGF&Beta;R2<br>
                        Supervisor: Dr. Mark Erwin
                    </li>
                </ul>
                <p></p>
                <h3 class="major">SKILLS AND INTERESTS</h2>
                <ul>
                    <li>Computer skills: Java, Python, PyTorch, NumPy, Pandas, Scikit-Learn, OpenCV, TensorFlow, MATLAB, R, SQL</li>
                    <li>Languages: Fluent professionally in English (native) and Mandarin (HSK 5 Certified)</li>
                    <li>Interests: Piano (RCM Level 10 Certified), visual arts, cooking, Chinese calligraphy</li>
                </ul>
                <p></p>
                <h3 class="major">EXPERIENCE</h3>
                <ul class="Alternate">
                    <li>
                        <b>Research Assistant</b>, 2022-2024<br>
                        Qian Lab, School of Biomedical Engineering, Shanghai Jiao Tong University<br>
                        <ul>
                            <li>Designed algorithms to improve video understanding of anatomical landmarks in colonoscopies</li>
                            <li>Fine-tuned and integrated LLMs to facilitate downstream video report generation</li>
                            <li>Preprocessed and built a large-scale dataset for the task of colonoscopy anatomical landmark recognition</li>
                        </ul>
                    </li>
                    <li>
                        <b>Research Assistant</b>, 2019-2020<br>
                        Erwin Lab, Toronto, ON, Canada<br>
                        <ul>
                            <li>Conducted research on spinal biological pathways associated with TGF&beta;R2</li>
                            <li>Performed extensive wet-labs such as Western Blotting and immunofluorescent staining 
                                to investigate protein fluctuations for finding gaps in spinal inflammation pathways 
                                to inform future research
                            </li>
                        </ul>
                    </li>
                </ul>
                <p></p>
                <h3 class="major">HONOURS AND AWARDS</h3>
                <ul>
                    <li>International Student Master's Program Full Scholarship, Shanghai Jiao Tong University</li>
                    <li>University of Toronto Scholar's Award</li>
                </ul>
                <h3 class="major">CERTIFICATIONS</h3>
                <ul>
                    <li>IBM Data Science Professional Certificate, 2022</li>
                    <li>Google Data Analytics Professional Certificate, 2022</li>
                    <li>Microsoft Certified: Azure Data Scientist Associate, 2021</li>
                    <li>Oracle Certified Professional: Java SE 11 Developer, 2021</li>
                </ul>
            </article>
            <!--contents for blog-->
            <article id="blog">
                <!-- <a href="#header" class="close"></a> -->
                <h2 class="major">Blog</h2>
                <span class="image main"><img src="images/tobermory_cropped.JPG" alt="" /></span>
                <figcaption>Picture taken at Tobermory, Ontario, Canada.</figcaption>
                
                <p></p>
                <h3 class="major">July 9, 2025</h3>
                <p>Turns out that the SVG line of code which I deleted from the .close section of
                    main.css was not actually a link to the background image, but for drawing 2 diagonals
                    to form the "X" of the close button. Reverting back to the default main.css script fixed
                    the disappearing close button problem. Sometimes going back to the drawing board can be the
                    solution after all.
                </p>
                <p>Modified background image to the main and the blog pages. Added descriptions in the About for the sources of
                    these images, in case anyone was wondering.
                </p>
                
                <h3 class="major">July 8, 2025</h3>
                <p>Modifying aesthetic template and trying to become more familiar with html in the process.
                    Why is the close icon not showing up on each sub-page???</p>
            
            </article>
            <!--contents for about-->
            <article id="about">
                <!-- <a href="#header" class="close"></a> -->
                <h2 class="major">About</h2>
                <blockquote>Aspiring Data Scientist with an interest in medical large language models (LLM) and computer vision.</blockquote>
                <p>The main page's background image was taken while on a trip to West Lake in Hangzhou, China (杭州西湖).
                    This image was chosen because it reflects serenity during a time when everything else in my life was hectic.
                    It also speaks to my philosophy in work and research, because often stepping back from a difficult problem and returning
                    with a calmer mindset leads to greater clarity. What once felt chaotic becomes organized, and viable solutions become more apparent. This pause also allows my brain to
                    integrate prior knowledge, enabling more effective reasoning and application.
                </p>
            </article>
            <!--contents for contact-->
            <article id="contact">
                <!-- <a href="#header" class="close"></a> -->
                <h2 class="major">Contact</h2>
                <!--<span class="image main"><img src="images/pic_item5.jpg" alt="" /></span>-->
                <form method="post" action="#">
                    <div class="fields">
                        <div class="field half">
                            <label for="name">Name</label>
                            <input type="text" name="name" id="name" />
                        </div>
                        <div class="field half">
                            <label for="email">Email</label>
                            <input type="text" name="email" id="email" />
                        </div>
                        <div class="field">
                            <label for="message">Message</label>
                            <textarea name="message" id="message" rows="4"></textarea>
                        </div>
                    </div>
                    <ul class="actions">
                        <li><input type="submit" value="Send Message" class="primary" /></li>
                        <li><input type="reset" value="Reset" /></li>
                    </ul>
                </form>
                <ul class="icons">
                    <li><a href="https://github.com/YUCXY" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
                </ul>
            </article>
        </div>
        <footer id="footer">
            <p>Design adapted from the Dimension template by <a href="https://html5up.net">HTML5 UP</a>.</p>
        </footer>
    </div>
    <!--background image-->
    <!--responsive nature means bg focuses on center-most region non-full-screen-->
    <div id="bg"></div>
    <!--scripts-->
    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/browser.min.js"></script>
    <script src="assets/js/breakpoints.min.js"></script>
    <script src="assets/js/util.js"></script>
    <script src="assets/js/main.js"></script>
</body>
</html>